Download a single file
wget http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.tar.bz2


Save/append messages to a file
  -a <file>
  --append-output=<file>


Log messages to a file
  -o <file>
  --output-file=<file>


Download a single file and save with another name
  Note: wget sometimes gets the extension wrong, example:
        http://www.vim.org/scripts/download_script.php?src_id=7701 is a zip file
        and when downloaded it is stored as download_script.php?src_id=7701
        to correct this use -O <new name> to specify a new name/extension
wget -O taglist.zip http://www.vim.org/scripts/download_script.php?src_id=7701


Downloading a list of files
wget -i download-file-list.txt


Save files to another directory
wget -P <local-directory> -i <download-list>


Skip downloading files that have already been downloaded
wget -nc -i <download-list>


Download a full website
wget --mirror -p --convert-links -P <local-directory> <website-url>


Download a website but reject certain files
    -R <comma separated list of filetypes>
    --reject=<comma separated list of filetypes>
  to ignore downloading files with those extensions

Download only certain files
    -A <comma separated list of filetypes>
    --accept=<comma separated list of filetypes>
  Specify a list of file extensions to accept while downloading


Accept downloading files from only certain domain(s)
    -D <comma separated list of domains to accept>
    --domains=<comma separated list of domains to accept>

Reject downloading files from certain domain(s)
    --exclude-domains=<comma separated list of domains to reject>


Limiting the download speed used by wget
  Use --limit-rate=200kb to limit the download speed to 200kbps
  Otherwise wget will use as much bandwidth as possible
wget --limit-rate=200k http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.tar.bz2


Continue an incompleted download
  Use the -c option to resume download of the file
    Note: if not using the -c option and the file is downloaded again a .1 will be
          appended to the end of the filename, ex: newsletter.pdf.1
          In the case the <name>.1 exists, .2, .3, etc will be used
          This is also the case when downloading a file that has been downloaded already
wget -c http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.tar.bz2


Download a large file in the background
  Use -b to initiate a download and allow you to use the shell while its downloading
  The progress will be written to wget-log
  To check progress of the download use:
tail -f wget-log


Download only new files
  Use -N or --timestamping
wget -N -i download-list.txt

Mask user agent
  Wget's headers can be used to tell the webpage it is not a browser
  Some websites may disallow the pages to be downloaded because of this
  To get around this use the --user-agent option to fool the website
wget --user-agent="Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko/2008092416 Firefox/3.0.3" <URL-TO-DOWNLOAD>


Save headers to file
wget --save-headers <url-to-download>


Check if a URL exists
  Use the --spider option to check if the remote file exists or not
wget --spider download-url


Send POST data
  Use --post-data=STRING
  or --post-data=FILE
wget --post-data=postData.dat <url-to-download>


Save rewritten urls
  By default wget doesn't save files with the simplified urls the server produces
  Using the --trust-server-names option will use the pretty urls instead of the originals
  Also the --content-disposition option can use a filename suggested by the server
  Both options can be used in combination

For more help use wget --help


Sources:
http://www.thegeekstuff.com/2009/09/the-ultimate-wget-download-guide-with-15-awesome-examples/
